{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Projet Integre</center></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run data_cleaning_libraries.py # on charge toutes les librairies et fonctions qui ont été crées. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(r'C:/Users/Romain/Desktop/fichiers_projets/publication.csv',delimiter=';',encoding='utf-16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "publication=data[data['categorie']=='article'].sample(500000,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_publication</th>\n",
       "      <th>date_pub</th>\n",
       "      <th>article_title</th>\n",
       "      <th>categorie</th>\n",
       "      <th>nbr_authors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1126526</th>\n",
       "      <td>journals/nar/NakamuraGI98</td>\n",
       "      <td>2020-05-17</td>\n",
       "      <td>Codon usage tabulated from the international DNA sequence databases.</td>\n",
       "      <td>article</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581201</th>\n",
       "      <td>journals/prl/EvansLCD06</td>\n",
       "      <td>2020-02-22</td>\n",
       "      <td>View synthesis for depth from motion 3D X-ray imaging.</td>\n",
       "      <td>article</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1258934</th>\n",
       "      <td>journals/fttcs/Vadhan12</td>\n",
       "      <td>2020-08-20</td>\n",
       "      <td>Pseudorandomness.</td>\n",
       "      <td>article</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2036919</th>\n",
       "      <td>journals/dm/KatonaQ93</td>\n",
       "      <td>2020-02-22</td>\n",
       "      <td>The largest component in a random subgraph of the n-cycle.</td>\n",
       "      <td>article</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518454</th>\n",
       "      <td>journals/cor/LabbeLS98</td>\n",
       "      <td>2020-02-18</td>\n",
       "      <td>Covering a graph with cycles.</td>\n",
       "      <td>article</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id_publication    date_pub  \\\n",
       "1126526  journals/nar/NakamuraGI98  2020-05-17   \n",
       "581201     journals/prl/EvansLCD06  2020-02-22   \n",
       "1258934    journals/fttcs/Vadhan12  2020-08-20   \n",
       "2036919      journals/dm/KatonaQ93  2020-02-22   \n",
       "518454      journals/cor/LabbeLS98  2020-02-18   \n",
       "\n",
       "                                                                article_title  \\\n",
       "1126526  Codon usage tabulated from the international DNA sequence databases.   \n",
       "581201                 View synthesis for depth from motion 3D X-ray imaging.   \n",
       "1258934                                                     Pseudorandomness.   \n",
       "2036919            The largest component in a random subgraph of the n-cycle.   \n",
       "518454                                          Covering a graph with cycles.   \n",
       "\n",
       "        categorie nbr_authors  \n",
       "1126526   article           3  \n",
       "581201    article           4  \n",
       "1258934   article           1  \n",
       "2036919   article           2  \n",
       "518454    article           3  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "publication.head() # Aperçu du fichier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "publication.drop(columns=['categorie','nbr_authors'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_publication</th>\n",
       "      <th>date_pub</th>\n",
       "      <th>article_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id_publication, date_pub, article_title]\n",
       "Index: []"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "publication[publication.duplicated()] # Doublons sur les lignes ? Non"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_publication</th>\n",
       "      <th>date_pub</th>\n",
       "      <th>article_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1745429</th>\n",
       "      <td>journals/scientometrics/Bar-Ilan08a</td>\n",
       "      <td>2020-07-17</td>\n",
       "      <td>The</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1877909</th>\n",
       "      <td>journals/clsr/Zajac87e</td>\n",
       "      <td>2020-10-13</td>\n",
       "      <td>US focus.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121345</th>\n",
       "      <td>journals/alife/Llarena10</td>\n",
       "      <td>2020-03-13</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>774677</th>\n",
       "      <td>journals/ejcon/Landau99</td>\n",
       "      <td>2017-05-28</td>\n",
       "      <td>Editorial.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1608745</th>\n",
       "      <td>journals/corr/BessiereRGKNNOP15</td>\n",
       "      <td>2018-08-13</td>\n",
       "      <td>The Inductive Constraint Programming Loop.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357617</th>\n",
       "      <td>journals/micro/X01f</td>\n",
       "      <td>2015-12-09</td>\n",
       "      <td>Micro News.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2055586</th>\n",
       "      <td>journals/sqj/Harrison18b</td>\n",
       "      <td>2020-06-08</td>\n",
       "      <td>In this issue.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1035320</th>\n",
       "      <td>journals/tpds/KleppmannB17</td>\n",
       "      <td>2020-10-02</td>\n",
       "      <td>A Conflict-Free Replicated JSON Datatype.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688859</th>\n",
       "      <td>journals/ieicet/Nagase18</td>\n",
       "      <td>2020-04-11</td>\n",
       "      <td>Foreword.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1812540</th>\n",
       "      <td>journals/cr/X11z</td>\n",
       "      <td>2018-07-03</td>\n",
       "      <td>Rechtsprechung zum Telekommunikationsrecht.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9166 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              id_publication    date_pub  \\\n",
       "1745429  journals/scientometrics/Bar-Ilan08a  2020-07-17   \n",
       "1877909               journals/clsr/Zajac87e  2020-10-13   \n",
       "121345              journals/alife/Llarena10  2020-03-13   \n",
       "774677               journals/ejcon/Landau99  2017-05-28   \n",
       "1608745      journals/corr/BessiereRGKNNOP15  2018-08-13   \n",
       "...                                      ...         ...   \n",
       "357617                   journals/micro/X01f  2015-12-09   \n",
       "2055586             journals/sqj/Harrison18b  2020-06-08   \n",
       "1035320           journals/tpds/KleppmannB17  2020-10-02   \n",
       "688859              journals/ieicet/Nagase18  2020-04-11   \n",
       "1812540                     journals/cr/X11z  2018-07-03   \n",
       "\n",
       "                                       article_title  \n",
       "1745429                                         The   \n",
       "1877909                                    US focus.  \n",
       "121345                                          None  \n",
       "774677                                    Editorial.  \n",
       "1608745   The Inductive Constraint Programming Loop.  \n",
       "...                                              ...  \n",
       "357617                                   Micro News.  \n",
       "2055586                               In this issue.  \n",
       "1035320    A Conflict-Free Replicated JSON Datatype.  \n",
       "688859                                     Foreword.  \n",
       "1812540  Rechtsprechung zum Telekommunikationsrecht.  \n",
       "\n",
       "[9166 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "publication[publication['article_title'].duplicated(keep=False)] # doublons sur les colonnes ! : plusieurs fois le même nom d'articles\n",
    "\n",
    "# Note : certaines publications de même titre ont des id_publication qui différent et certaines ont des dates différentes \n",
    "# pour un même id_publication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_rows = publication[publication['article_title'].duplicated(keep='first')] # suppression des doublons sur les colonnes \n",
    "publication.drop(delete_rows.index,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "492460"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(publication)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_publication</th>\n",
       "      <th>date_pub</th>\n",
       "      <th>article_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1651163</th>\n",
       "      <td>journals/corr/abs-1912-10764</td>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>Layerwise Noise Maximisation to Train Low-Energy Deep Neural Networks.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1638180</th>\n",
       "      <td>journals/corr/abs-1912-12122</td>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>Deep Learning Based Android Malware Detection Framework.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1544252</th>\n",
       "      <td>journals/corr/abs-1912-07909</td>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>Condition number bounds for IETI-DP methods that are explicit in h and p.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1483519</th>\n",
       "      <td>journals/corr/abs-1912-11919</td>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>A new spectral method based on two classes of hat functions for solving systems of fractional differential equations and an application to respiratory syncytial virus infection.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1386347</th>\n",
       "      <td>journals/corr/abs-1912-07314</td>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>On Opacity Verification for Discrete-Event Systems.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id_publication    date_pub  \\\n",
       "1651163  journals/corr/abs-1912-10764  2020-01-03   \n",
       "1638180  journals/corr/abs-1912-12122  2020-01-03   \n",
       "1544252  journals/corr/abs-1912-07909  2020-01-03   \n",
       "1483519  journals/corr/abs-1912-11919  2020-01-03   \n",
       "1386347  journals/corr/abs-1912-07314  2020-01-03   \n",
       "\n",
       "                                                                                                                                                                             article_title  \n",
       "1651163                                                                                                             Layerwise Noise Maximisation to Train Low-Energy Deep Neural Networks.  \n",
       "1638180                                                                                                                           Deep Learning Based Android Malware Detection Framework.  \n",
       "1544252                                                                                                          Condition number bounds for IETI-DP methods that are explicit in h and p.  \n",
       "1483519  A new spectral method based on two classes of hat functions for solving systems of fractional differential equations and an application to respiratory syncytial virus infection.  \n",
       "1386347                                                                                                                                On Opacity Verification for Discrete-Event Systems.  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "publication.sort_values(by=['date_pub'])[132000:].head() #26 % documents antérieurs à 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_dict(publication,'df_new_data') # nécessite de creer dans l'espace de travail un dossier nommé dict2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:red\">1er nettoyage : suppression des balises et des caractères indésirables (voir fonction cleaning_1)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_titles = publication[\"article_title\"].str.lower() # conversion des articles en minuscle\n",
    "article_titles = article_titles.tolist() # conversion des articles en liste\n",
    "\n",
    "list_id_publication = list(publication['id_publication']) # liste des identifiants\n",
    "\n",
    "article_titles = dict(zip(list_id_publication,article_titles)) # articles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_dict(article_titles, \"original_titles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_titles = load_dict(\"original_titles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaning_1(article_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'journals/nar/NakamuraGI98': 'codon usage tabulated from the international dna sequence databases ',\n",
       " 'journals/prl/EvansLCD06': 'view synthesis for depth from motion 3d x ray imaging ',\n",
       " 'journals/fttcs/Vadhan12': 'pseudorandomness ',\n",
       " 'journals/dm/KatonaQ93': 'the largest component in a random subgraph of the n cycle ',\n",
       " 'journals/cor/LabbeLS98': 'covering a graph with cycles '}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(list(article_titles.items())[0:5]) # affichage des 5 premiers éléments du dictionnaire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:orange\">Sauvegarde</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_dict(article_titles, \"firstclean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_titles = load_dict(\"firstclean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:red\"> 2ème nettoyage : Suppression de la ponctuation, des tirets des nombres...(voir fonction cleaning)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaning_2(article_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'journals/nar/NakamuraGI98': 'codon usage tabulated from the international dna sequence databases ',\n",
       " 'journals/prl/EvansLCD06': 'view synthesis for depth from motion 3d x ray imaging ',\n",
       " 'journals/fttcs/Vadhan12': 'pseudorandomness ',\n",
       " 'journals/dm/KatonaQ93': 'the largest component in a random subgraph of the n cycle ',\n",
       " 'journals/cor/LabbeLS98': 'covering a graph with cycles '}"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(list(article_titles.items())[0:5]) # affichage des 5 premiers éléments du dictionnaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_dict(article_titles, \"secondclean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_titles = load_dict(\"secondclean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:red\"> 3ème nettoyage :  Suppression des chaines de caractères référencant des dates ou des pays, suppression de certains mots, suppression des espaces en trop.. (voir fonction cleaning_3) </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaning_3(article_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in article_titles.copy(): # test de la présence dans la chaine de l'unique présence de characteres spéciaux\n",
    "    # car cela peut causer une erreur dans le test de détection de la langue qui va être fait par la suite\n",
    "    if re.match(r'^[_\\W]+$',article_titles[i]):\n",
    "        del article_titles[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dict(article_titles, \"all_languages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_titles = load_dict(\"all_languages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "492196"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(article_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matching = [s for s in article_titles.values() if '' in s] # test de la présence d'un mot\n",
    "matching[0:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:red\"> Sélection des articles qui sont uniquements en anglais </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_english(article_titles) # Suppresion de plus de 43 000 articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_titles = dict(list(article_titles.items())[0:400000]) # on va travailler sur une base de 400 000 documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_dict(article_titles, \"only_english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_titles = load_dict(\"only_english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400000"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(article_titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:red\">Suppression des stop words</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenisation des titres\n",
    "\n",
    "tokenizer = nltk.RegexpTokenizer(r'\\w+')\n",
    "tokenized_titles = defaultdict(set)\n",
    "for k,v in article_titles.items() :\n",
    "    article_titles[k] = tokenizer.tokenize(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_dict(article_titles, \"tokenized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_titles = load_dict(\"tokenized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozenset({'others', 'serious', 'they', 'enough', 'up', \"doesn't\", 'eleven', 'five', \"haven't\", 'might', 'next', 'itself', 'o', 'had', 'various', 'until', 'whereas', \"hasn't\", 'wasn', 'thick', 'doing', 'myself', \"don't\", 'own', 'name', 'isn', 'm', \"you'd\", 'toward', 'needn', 'whereby', 'without', \"aren't\", 'hereupon', 'anything', 'if', \"she's\", 'behind', 'beforehand', 'whether', 'ma', 'twelve', 'y', 'with', 'i', 'mostly', 'km', 'describe', 'take', 'fifteen', 'regarding', 'fire', 'about', 'whereupon', 'anyhow', 'kg', 'couldn', 'therefore', 'forty', 'whoever', 'seems', 'system', 'been', 'shan', 'alone', 'go', 'on', 'whither', 'becomes', 'thereby', 'although', 'computer', 'themselves', 'off', 'shouldn', 'how', \"shouldn't\", \"isn't\", 'nine', 'have', 'into', 'should', 'them', \"needn't\", 're', 'ten', 'latter', 'three', 'part', 'was', 'everywhere', 'down', 'didn', 'he', 'thus', 'already', 'everything', 'too', 'as', \"couldn't\", \"wouldn't\", 'eg', 'moreover', 'did', 'by', 'per', 'also', 'it', 'do', 'most', 'what', 'ie', 'everyone', \"should've\", 'thence', 'were', 'all', 'six', 'full', 'due', 'none', 'before', 'yet', 'for', 'these', 'yourself', 'a', 'anyone', 'same', 'herein', \"that'll\", 'than', 'between', 'somehow', 'whatever', 'mine', 'she', 'sincere', 'detail', 'rather', 'an', 'please', 'whenever', 'along', 'herself', 'hasnt', 'there', 'fill', 'their', 'during', 'beyond', 'amoungst', \"mustn't\", 'd', 'besides', 'seemed', 'move', 'quite', 'any', 'yours', 'via', \"didn't\", 'co', 'hereby', 'very', 'but', 'being', 'we', 'say', 'haven', 'always', 'wouldn', 'ours', 'now', 'or', 'anyway', 'from', 'hadn', 'few', 'below', 'former', 'against', \"you're\", 'bill', 'whose', 'un', 'otherwise', 'noone', 'doesn', 'etc', 'thru', 'last', 'her', 'whence', 'top', 'hers', 'get', 'may', 'so', 'ever', 'many', 'side', 'hence', 'your', 'thereafter', 'another', 'which', 'me', 'afterwards', 'nowhere', 'not', 'elsewhere', 'sixty', 'other', 'the', 'indeed', 'won', 'cannot', 'using', 'unless', 'mightn', 'inc', 'yourselves', 'would', 'him', 'though', 'must', 'upon', 'onto', 'here', 'nevertheless', 'be', 'empty', 'every', 'throughout', 'became', 'made', 'done', 'eight', 'put', \"weren't\", 'cry', 'ourselves', 'even', 'nor', 'interest', 'across', 'either', 'again', 'don', 'much', 'will', 've', 'at', 'thereupon', 'something', 'call', 'keep', 'nothing', 'see', 'wherever', 'meanwhile', 'is', 'its', 'perhaps', 'else', 'no', 'and', 'therein', 'namely', 'within', 'bottom', 'latterly', 'mustn', \"mightn't\", 'can', 'hundred', 'two', 'through', 'll', 'having', 'make', 'both', \"won't\", 'then', 'this', 'you', 'together', 'seem', 'almost', 'less', 'amongst', 'twenty', 'still', 'except', 'de', 'to', 'give', 'that', 'himself', \"hadn't\", 't', 'ltd', 'such', 'hasn', 'only', 'thin', \"it's\", \"you'll\", 'does', 'third', 'formerly', 'find', 'beside', 'mill', 'seeming', 'after', 'one', 'more', 'con', 'around', 'our', 'since', 'those', 'anywhere', \"shan't\", 'us', \"you've\", 'four', 'who', 'least', 'someone', 'towards', 'front', 'neither', 'whole', 'fifty', 'under', 'could', 'cant', 'hereafter', 'whom', 'out', 'found', 'sometime', 'while', 'my', 'some', 'in', \"wasn't\", 'just', 'nobody', 'becoming', 'first', 'theirs', 'am', 'often', 'become', 'used', 's', 'his', 'each', 'whereafter', 'ain', 'show', 'never', 'where', 'when', 'sometimes', 'above', 'why', 'further', 'are', 'somewhere', 'well', 'among', 'weren', 'amount', 'back', 'of', 'once', 'really', 'has', 'aren', 'because', 'over', 'couldnt', 'however', 'several', 'wherein'})\n"
     ]
    }
   ],
   "source": [
    "# suppression des mots vides\n",
    "delete_stop_words(article_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in article_titles.items() :\n",
    "    article_titles[k] = [word for word in v if word not in all_stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_dict(article_titles, \"nostopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_titles = load_dict(\"nostopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'journals/nar/NakamuraGI98': ['codon',\n",
       "  'usage',\n",
       "  'tabulated',\n",
       "  'dna',\n",
       "  'sequence',\n",
       "  'databases'],\n",
       " 'journals/prl/EvansLCD06': ['view',\n",
       "  'synthesis',\n",
       "  'depth',\n",
       "  'motion',\n",
       "  '3d',\n",
       "  'ray',\n",
       "  'imaging'],\n",
       " 'journals/dm/KatonaQ93': ['largest',\n",
       "  'component',\n",
       "  'random',\n",
       "  'subgraph',\n",
       "  'cycle'],\n",
       " 'journals/cor/LabbeLS98': ['covering', 'graph', 'cycles'],\n",
       " 'journals/ita/GaibissoGT90': ['partially',\n",
       "  'persistent',\n",
       "  'data',\n",
       "  'structure',\n",
       "  'set',\n",
       "  'union',\n",
       "  'problem']}"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(list(article_titles.items())[0:5]) # affichage des 5 premiers éléments du dictionnaire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:red\">Lemmatisation + correction suite au notebook visualisation + suppression des articles de moins de 3 mots</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatisation(article_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_dict(article_titles, \"lemmatized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_titles = load_dict(\"lemmatized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'journals/nar/NakamuraGI98': ['codon',\n",
       "  'usage',\n",
       "  'tabulate',\n",
       "  'dna',\n",
       "  'sequence',\n",
       "  'database'],\n",
       " 'journals/prl/EvansLCD06': ['view',\n",
       "  'synthesis',\n",
       "  'depth',\n",
       "  'motion',\n",
       "  '3d',\n",
       "  'ray',\n",
       "  'image'],\n",
       " 'journals/dm/KatonaQ93': ['large',\n",
       "  'component',\n",
       "  'random',\n",
       "  'subgraph',\n",
       "  'cycle'],\n",
       " 'journals/cor/LabbeLS98': ['cover', 'graph', 'cycle'],\n",
       " 'journals/ita/GaibissoGT90': ['partially',\n",
       "  'persistent',\n",
       "  'data',\n",
       "  'structure',\n",
       "  'set',\n",
       "  'union',\n",
       "  'problem']}"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(list(article_titles.items())[0:5]) # affichage des 5 premiers éléments du dictionnaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_titles = load_dict(\"lemmatized_without_based\") # suite à la visualisation des données du notebook visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict(list(article_titles.items())[0:5]) # affichage des 5 premiers éléments du dictionnaireart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppression des articles qui font moins de 3 mots\n",
    "nb=0\n",
    "for key, val in article_titles.copy().items():\n",
    "    if (len(article_titles[key])<3):\n",
    "        del(article_titles[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "394039"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(article_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_dict(article_titles, \"lemmatized_more_than_2_words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_titles_token_dict=load_dict('lemmatized_more_than_2_words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys=list(article_titles_token_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "394039"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_titles_str_lst = []\n",
    "lst = list(article_titles_token_dict.values())\n",
    "\n",
    "for i in lst:\n",
    "    a=\" \".join([k for k in i])\n",
    "    article_titles_str.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_dict(article_titles_str, \"article_titles_str_lst\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_titles_str=load_dict(\"article_titles_str_lst\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['codon usage tabulate dna sequence database',\n",
       " 'view synthesis depth motion 3d ray image',\n",
       " 'large component random subgraph cycle',\n",
       " 'cover graph cycle',\n",
       " 'partially persistent data structure set union problem']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_titles_str[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_titles_token_dict = load_dict(\"article_title_token_dict\") # = lemmatized_more_than_2_words (après duplication et renommage du pickle)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_titles_str_lst = load_dict(\"article_titles_str_lst\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'journals/nar/NakamuraGI98': ['codon',\n",
       "  'usage',\n",
       "  'tabulate',\n",
       "  'dna',\n",
       "  'sequence',\n",
       "  'database'],\n",
       " 'journals/prl/EvansLCD06': ['view',\n",
       "  'synthesis',\n",
       "  'depth',\n",
       "  'motion',\n",
       "  '3d',\n",
       "  'ray',\n",
       "  'image'],\n",
       " 'journals/dm/KatonaQ93': ['large',\n",
       "  'component',\n",
       "  'random',\n",
       "  'subgraph',\n",
       "  'cycle'],\n",
       " 'journals/cor/LabbeLS98': ['cover', 'graph', 'cycle'],\n",
       " 'journals/ita/GaibissoGT90': ['partially',\n",
       "  'persistent',\n",
       "  'data',\n",
       "  'structure',\n",
       "  'set',\n",
       "  'union',\n",
       "  'problem']}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(list(article_titles_token_dict.items())[0:5]) # affichage des 5 premiers éléments du dictionnaireart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['codon usage tabulate dna sequence database',\n",
       " 'view synthesis depth motion 3d ray image',\n",
       " 'large component random subgraph cycle',\n",
       " 'cover graph cycle',\n",
       " 'partially persistent data structure set union problem']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_titles_str_lst[0:5]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
